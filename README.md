<div align="center">

<br/>

```
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘    â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•  
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â•šâ•â•  â•šâ•â•â•šâ•â•     â•šâ•â•â•â•   â•šâ•â•â•â•â•â• â•šâ•â• â•šâ•â•â•â•â•â•â•šâ•â•â•â•â•â•â•
     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â•šâ•â•â–ˆâ–ˆâ•”â•â•â•
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   
    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   
    â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•â•â•â•â•â•  â•šâ•â•   â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•â•  â•šâ•â•   
```

# ğŸ™ï¸ AI Voice Assistant

**A Modern Offline-First AI Assistant with Voice, Chat & Beyond**  
_Real-time Speech-to-Text Â· GPT Integration Â· Text-to-Speech Â· Chat Interface Â· Sub-1.2s Response_

<br/>

[![Next.js](https://img.shields.io/badge/Next.js_15-000000?style=for-the-badge&logo=next.js&logoColor=white)](https://nextjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![TailwindCSS](https://img.shields.io/badge/TailwindCSS-06B6D4?style=for-the-badge&logo=tailwindcss&logoColor=white)](https://tailwindcss.com/)
[![OpenAI](https://img.shields.io/badge/OpenAI_GPT-412991?style=for-the-badge&logo=openai&logoColor=white)](https://openai.com/)
[![PWA](https://img.shields.io/badge/PWA_Ready-10B981?style=for-the-badge&logo=googlechrome&logoColor=white)](#)
[![Voice](https://img.shields.io/badge/Voice_Enabled-FF4F00?style=for-the-badge&logo=googlepodcasts&logoColor=white)](#)
[![Chat](https://img.shields.io/badge/Chat_Interface-1D9BF0?style=for-the-badge&logo=chatbot&logoColor=white)](#)

<br/>

[![MIT License](https://img.shields.io/badge/License-MIT-emerald?style=flat-square)](LICENSE)
[![Node](https://img.shields.io/badge/Node.js-v18%2B-339933?style=flat-square&logo=node.js&logoColor=white)](https://nodejs.org/)
[![PRs Welcome](https://img.shields.io/badge/PRs-Welcome-10B981?style=flat-square)](CONTRIBUTING.md)
[![Status](https://img.shields.io/badge/Status-Active-10B981?style=flat-square)](#)

<br/>

> **âš¡ Live Demo â†’** [Launch AI Voice Assistant](#) _(add your deployed URL here)_

<br/>

---

</div>

## ğŸ§  What Is This?

**AI Voice Assistant** is a Next.js Progressive Web App that brings a **full-featured AI assistant** directly to your browser â€” powered by OpenAI GPT and built around a seamless voice-first experience, with text chat, real-time transcription, and spoken responses all in one.

No native app. No backend servers. No friction.

```
ğŸ™ï¸ Voice Mode          ğŸ’¬ Chat Mode
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Mic Input              Text Input
    â†“                      â†“
STT Worker             Direct Input
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
       ğŸ¤– OpenAI GPT
               â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                     â†“
ğŸ”Š TTS Worker         ğŸ’¬ Chat Display
Audio Playback        Text Response

     All processing: sub-1.2s end-to-end
```

Built for developers and power users who want a **fast, installable, offline-capable** AI assistant â€” voice or chat, your choice, without the bloat.

<br/>

---

## âœ¨ Feature Breakdown

<table>
<tr>
<td width="50%">

### ğŸ™ï¸ Voice Input
- Real-time Speech Recognition via Web Speech API  
- Low-latency audio capture pipeline  
- Web Worker offloading â€” zero UI thread blocking  
- Smart start/stop toggle interface  

</td>
<td width="50%">

### ğŸ¤– AI Processing
- OpenAI GPT via serverless API route  
- Secure server-side key handling  
- Efficient token-aware request architecture  
- Response streamed to TTS pipeline  

</td>
</tr>
<tr>
<td width="50%">

### ğŸ”Š Audio Output
- Web Speech Synthesis (TTS)  
- Natural voice playback  
- Fully background-processed  
- Configurable voice & rate settings  

</td>
<td width="50%">

### ğŸ“± Progressive Web App
- Installable on desktop & mobile  
- Offline capability via Service Worker  
- Aggressive asset caching strategy  
- Manifest-configured PWA metadata  

</td>
</tr>
<tr>
<td width="50%">

### âš¡ Performance
- **Sub-1.2s** end-to-end latency target  
- Real-time latency tracking (displayed in UI)  
- Optimized Next.js 15 App Router rendering  
- Minimal reflow, paint-optimized pipeline  

</td>
<td width="50%">

### ğŸ—ï¸ Architecture
- TypeScript throughout â€” fully type-safe  
- Clean separation of concerns  
- Serverless-friendly deployment  
- Scalable component structure  

</td>
<td width="50%">

### ğŸ’¬ Chat Interface
- Text-based input alongside voice  
- Persistent conversation display  
- Message history & context passing  
- Seamless voice â†” chat switching  

</td>
</tr>
</table>

<br/>

---

## ğŸ“ Project Structure

```
ai-voice-assistant/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ chat/               # ğŸ¤– OpenAI API route (serverless)
â”‚   â”‚       â””â”€â”€ route.ts
â”‚   â”œâ”€â”€ components/             # ğŸ§© Feature components
â”‚   â”‚   â”œâ”€â”€ VoiceButton.tsx
â”‚   â”‚   â”œâ”€â”€ ResponseDisplay.tsx
â”‚   â”‚   â””â”€â”€ LatencyTracker.tsx
â”‚   â”œâ”€â”€ layout.tsx              # App shell & metadata
â”‚   â”œâ”€â”€ page.tsx                # Entry page
â”‚   â””â”€â”€ globals.css             # Global + Tailwind styles
â”‚
â”œâ”€â”€ components/
â”‚   â””â”€â”€ ui/                     # ğŸ¨ Reusable UI primitives
â”‚
â”œâ”€â”€ lib/                        # ğŸ› ï¸ Utilities & helpers
â”‚
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â”œâ”€â”€ stt.worker.js       # ğŸ™ï¸ Speech-to-Text Web Worker
â”‚   â”‚   â””â”€â”€ tts.worker.js       # ğŸ”Š Text-to-Speech Web Worker
â”‚   â”œâ”€â”€ manifest.json           # ğŸ“± PWA manifest
â”‚   â””â”€â”€ sw.js                   # âš™ï¸  Service Worker
â”‚
â”œâ”€â”€ .env.local                  # ğŸ” Environment variables (not committed)
â”œâ”€â”€ .env.local.example          # ğŸ“‹ Env template
â”œâ”€â”€ next.config.ts              # âš™ï¸  Next.js config
â””â”€â”€ tsconfig.json
```

<br/>

---

## âš¡ Getting Started

### Prerequisites

| Requirement | Version |
|-------------|---------|
| Node.js     | `v18+`  |
| npm         | `v8+`   |
| OpenAI API Key | [Get one here â†’](https://platform.openai.com/api-keys) |

<br/>

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/ai-voice-assistant.git
cd ai-voice-assistant
```

### 2ï¸âƒ£ Install Dependencies

```bash
npm install
```

### 3ï¸âƒ£ Configure Environment Variables

```bash
cp .env.local.example .env.local
```

Open `.env.local` and add your key:

```env
# .env.local
OPENAI_API_KEY=sk-your_openai_api_key_here
```

> ğŸ”’ **Never commit `.env.local` to version control.**

### 4ï¸âƒ£ Start the Development Server

```bash
npm run dev
```

Open your browser at:

```
http://localhost:3000
```

<br/>

---

## ğŸ¯ How to Use

**ğŸ™ï¸ Voice Mode**
```
1.  Open the app in a modern browser (Chrome recommended for full STT support)
2.  Click the ğŸ™ï¸  microphone button to start recording
3.  Speak your query naturally
4.  Click again to stop recording
5.  Watch the latency counter as the AI processes your request
6.  Listen as the response is spoken back to you via TTS
```

**ğŸ’¬ Chat Mode**
```
1.  Type your message in the chat input box
2.  Press Enter or click Send
3.  Read the AI response in the conversation thread
4.  Optionally click ğŸ”Š to have the response read aloud
```

> ğŸ’¡ **Tip:** Install as a PWA from your browser's address bar for a native app-like experience on any device.

<br/>

---

## ğŸ§ª Performance Targets

| Metric | Target | Notes |
|--------|--------|-------|
| End-to-end latency | **< 1.2s** | STT â†’ API â†’ TTS |
| STT processing | **< 200ms** | Web Worker, off main thread |
| OpenAI API response | **< 800ms** | Serverless edge route |
| TTS synthesis start | **< 100ms** | Native browser synthesis |
| PWA install size | **< 500KB** | Cached assets |

<br/>

---

## ğŸ”® Roadmap

- [ ] ğŸ§  **Conversation memory** â€” contextual multi-turn dialogue  
- [ ] ğŸŒ **Multi-language support** â€” STT & TTS in 10+ languages  
- [ ] ğŸ” **Secure session handling** â€” auth-gated usage  
- [ ] ğŸ“Š **Conversation analytics** â€” history, usage stats, export  
- [ ] ğŸ¨ **Voice themes** â€” custom TTS voice selection  
- [ ] ğŸŒ™ **Dark / Light mode toggle**  
- [ ] ğŸ“¡ **Streaming responses** â€” token-by-token TTS output  

<br/>

---

## ğŸ¤ Contributing

Contributions are welcome and appreciated!

```bash
# 1. Fork the repo
# 2. Create your feature branch
git checkout -b feature/amazing-feature

# 3. Commit with conventional commits
git commit -m "feat: add amazing feature"

# 4. Push to your fork
git push origin feature/amazing-feature

# 5. Open a Pull Request ğŸš€
```

Please follow [conventional commits](https://www.conventionalcommits.org/) and keep PRs focused.

<br/>

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

```
MIT License â€” free to use, modify, and distribute.
Attribution appreciated but not required.
```

<br/>

---

<div align="center">

**Built by [Pendalwar Sainath](https://github.com/your-username)**  
_Systems-focused Full-Stack Developer Â· AI & Performance Enthusiast_

<br/>

[![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/your-username)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/your-profile)
[![Portfolio](https://img.shields.io/badge/Portfolio-10B981?style=for-the-badge&logo=vercel&logoColor=white)](https://your-portfolio.dev)

<br/>

_If this project helped you, consider leaving a â­ â€” it means a lot!_

<br/>

---

<sub>Made with precision Â· Optimized for performance Â· Built to last</sub>

</div>
